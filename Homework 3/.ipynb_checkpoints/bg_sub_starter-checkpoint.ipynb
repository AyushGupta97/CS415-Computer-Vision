{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Homework 3\n",
    "--------------\n",
    "Four parts to this problem:\n",
    "\ta) Reading a stream of images from a webcamera or folder, and displaying the video\n",
    "\tb) Threshold based detection\n",
    "\tc) Background differencing\n",
    "\td) Visualizing motion history\n",
    "--------------\n",
    "'''\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np #for math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((5,5)) #basic debugging tool in math is still to print them and check manually!\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = a > 0.5 #See how logical operations can be used to thresholding?\n",
    "print(mask.all() or mask.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in code in these definitions\n",
    "def my_threshold_detect(src):\n",
    "    '''\n",
    "    Function that detects whether a pixel belongs to the foreground on RGB values\n",
    "    Args: \n",
    "        src The source color image\n",
    "    Returns: \n",
    "        dst The destination grayscale image where foreground pixels are colored white and the rest are colored black\n",
    "    \n",
    "    '''\n",
    "    gray_image = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    # ret, dst = cv2.threshold(gray_image, 210, 255, cv2.THRESH_BINARY)\n",
    "    # selecting the pre-determined threshold = 210\n",
    "    dst = (gray_image > 210).astype(np.uint8)*255\n",
    "    return dst\n",
    "    pass\n",
    "\n",
    "def my_frame_differencing(prev, curr):\n",
    "    '''\n",
    "    Function that does frame differencing between the current frame and the previous frame\n",
    "    Args:\n",
    "        src The current color image\n",
    "        prev The previous color image\n",
    "    Returns:\n",
    "        dst The destination grayscale image where pixels are colored white if the corresponding pixel intensities in the current\n",
    "    and previous image are not the same\n",
    "    '''\n",
    "    gray_curr = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "    gray_prev = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "    difference = cv2.absdiff(gray_curr, gray_prev)\n",
    "    # selecting the pre-determined threshold = 40\n",
    "    dst = (difference > 20).astype(np.uint8)*255\n",
    "    return dst\n",
    "    pass\n",
    "\n",
    "def my_frame_differencing_adaptive(prev, curr):\n",
    "    gray_curr = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "    gray_prev = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "    difference = cv2.absdiff(gray_curr, gray_prev)\n",
    "    ret, dst = cv2.threshold(difference, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return dst\n",
    "    pass\n",
    "\n",
    "def my_frame_differencing_mean(prev_frames, curr):\n",
    "    background = prev_frames[0]\n",
    "    for i in range(len(prev_frames)):\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            alpha = 1.0/(i + 1)\n",
    "            beta = 1.0 - alpha\n",
    "            background = cv2.addWeighted(prev_frames[i], alpha, background, beta, 0.0) \n",
    "    gray_curr = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "    gray_prev = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    difference = cv2.absdiff(gray_curr, gray_prev)\n",
    "    dst = (difference > 40).astype(np.uint8)*255\n",
    "    return dst\n",
    "    pass\n",
    "\n",
    "def my_motion_energy(mh):\n",
    "    '''\n",
    "    Function that accumulates the frame differences for a certain number of pairs of frames\n",
    "    Args:\n",
    "        mh Vector of frame difference images\n",
    "    Returns:\n",
    "        dst The destination grayscale image to store the accumulation of the frame difference images\n",
    "    '''\n",
    "    mh1 = cv2.add(mh[0], mh[1])\n",
    "    return cv2.add(mh[0], mh1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# a) Reading a stream of images from a webcamera, and displaying the video\n",
    "# ----------------\n",
    "# For more information on reading and writing video: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html\n",
    "# open the video camera no. 0\n",
    "# Fill in code to read the given video file. \n",
    "cap = cv2.VideoCapture(\"railway2.avi\")\n",
    "\n",
    "\n",
    "\n",
    "# if not successful, exit program\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open the video cam or file\")\n",
    "    sys.exit()\n",
    "\n",
    "# create a window called \"MyVideo0\"\n",
    "# cv2.namedWindow(\"MyVideo0\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# read a new frame from video\n",
    "ret, frame0 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Cannot read a frame from video stream\")\n",
    "\n",
    "# show the frame in \"Webcam\" window\n",
    "#cv2.imshow(\"Webcam\", frame0)\n",
    "w = int(cap.get(3))\n",
    "h = int(cap.get(4))\n",
    "out_1 = cv2.VideoWriter('threshold_tracker.avi', 0, 30, (w,h),0)\n",
    "out_2 = cv2.VideoWriter('framediff_nonadaptive.avi', 0, 30, (w,h),0)\n",
    "out_3 = cv2.VideoWriter('framediff_adaptive.avi', 0, 30, (w,h),0)\n",
    "out_4 = cv2.VideoWriter('framediff_mean.avi', 0, 30, (w,h),0)\n",
    "out_5 = cv2.VideoWriter('motionhistory.avi', 0, 30, (w,h),0)\n",
    "out_6 = cv2.VideoWriter('Compare.avi', 0, 30, (w,h), 0)\n",
    "\n",
    "# create windows\n",
    "# cv2.namedWindow(\"MyVideo\", cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.namedWindow(\"FrameDiff\", cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.namedWindow(\"MotionEnergy\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "my_motion_history = []\n",
    "\n",
    "mean_frames = list()\n",
    "while(1): #playing the video\n",
    "    # read a new frame from video\n",
    "    ret, frame = cap.read()\n",
    "    # if not successful, break loop\n",
    "    if not ret:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "        break\n",
    "\n",
    "    #cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    # ----------------\n",
    "    # b) Threshold based detection\n",
    "    # ----------------\n",
    "    frame_dst1 = my_threshold_detect(frame)\n",
    "    out_1.write(frame_dst1)\n",
    "    #cv2.imshow(\"Threshold\", frame_dst1)\n",
    "\n",
    "    # ----------------\n",
    "    # c) Background differencing\n",
    "    # ----------------\n",
    "\n",
    "    # call my_frame_differencing - Non Adaptive function\n",
    "    frame_dst2 = my_frame_differencing(frame0, frame)\n",
    "    out_2.write(frame_dst2)\n",
    "    #cv2.imshow(\"FrameDiff Non-Adaptive\", frame_dst2)\n",
    "    \n",
    "    # call my_frame_differencing - Adaptive function\n",
    "    frame_dst3 = my_frame_differencing_adaptive(frame0, frame)\n",
    "    out_3.write(frame_dst3)\n",
    "    #cv2.imshow(\"FrameDiff Adaptive\", frame_dst3)\n",
    "    frame_dst4 = frame_dst3\n",
    "    # call my_frame_differencing - mean function\n",
    "    mean_frames.append(frame)\n",
    "    if len(mean_frames) > 5:\n",
    "        frame_dst4 = my_frame_differencing_mean(mean_frames, frame)\n",
    "        mean_frames.pop(0)\n",
    "        out_4.write(frame_dst4)\n",
    "        #cv2.imshow(\"FrameDiff Mean\", frame_dst4)\n",
    "        \n",
    "    # Fill in code to update motion history\n",
    "     \n",
    "    # ----------------\n",
    "    #  d) Visualizing motion history\n",
    "    # ----------------\n",
    "    \n",
    "    # Add some frames initially to create motion history, here I used 3.\n",
    "    frame_dstmh = my_frame_differencing(frame0, frame)\n",
    "    myMH = frame_dstmh\n",
    "    my_motion_history.append(frame_dstmh)\n",
    "    if len(my_motion_history) > 4:\n",
    "        # call my_motion_energy function\n",
    "        myMH = my_motion_energy(my_motion_history)\n",
    "        #cv2.imshow(\"MotionEnergy\", myMH)\n",
    "        my_motion_history.pop(0)\n",
    "    out_5.write(myMH)\n",
    "    \n",
    "    # Quantative \n",
    "    cv2.putText(frame_dst1, 'Threshold Tracker', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "    cv2.putText(frame_dst2, 'Non Adaptive', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "    cv2.putText(frame_dst3, 'Adaptive', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "    cv2.putText(frame_dst4, 'Mean', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "\n",
    "    multi_frame = np.hstack((np.vstack((frame_dst1, frame_dst2)), np.vstack((frame_dst3, frame_dst4))))\n",
    "    cv2.imshow(\"Quantative\", multi_frame)\n",
    "    out_6.write(multi_frame)\n",
    "    frame0 = frame\n",
    "\n",
    "    # wait for 'esc' key press for 30ms. If 'esc' key is pressed, break loop\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"esc key is pressed by user\")\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
